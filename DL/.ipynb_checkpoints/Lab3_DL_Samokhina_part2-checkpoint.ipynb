{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа по DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Almost Shakespeare \n",
    "Генерация текста с помощью нейронных сетей. \n",
    "\n",
    "Обучить нейронную сеть на сонетах Шекспира и нейросетью написать свой сонет.\n",
    "\n",
    "Генерация текста обычно включает в себя следующие шаги:\n",
    "    \n",
    "1. Загрузка данных.\n",
    "2. Создание словарей слов/символов.\n",
    "3. Препроцессинг данных.\n",
    "4. Обучение модели (нейросети).\n",
    "5. Генерация нового текста.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Часть 1. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим данные. Файл с сонетами Шекспира доступен по [ссылке](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). Кроме того, он находится рядом с этим ноутбуком (`sonnetes.txt`).\n",
    "\n",
    "Базовая предобработка уже сделана: текст состоит непосредственно из поэм Шекспира и названий/номеров глав, все техническая информация удалена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START:TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в этот раз мы хотим научиться предсказывать текст, понизим сложность задачи и приведем текст к нижнему регистру.\n",
    "\n",
    "В настоящий момент переменная `text` представляет собой список из строк. Объедините все строки в одну и приведите к нижнему регистру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отлично!\n"
     ]
    }
   ],
   "source": [
    "# Объедините все строки в одну и приведите к нижнему регистру.\n",
    "# Результат запишите в переменную text.\n",
    "\n",
    "# Your great code here\n",
    "import string\n",
    "\n",
    "text = ''.join(text)\n",
    "text = text.lower()\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('Отлично!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделите множество всех символов, с которыми нам довелось встретиться в переменную `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте словарь `token_to_idx` вида <символ>: <индекс> и словарь `idx_to_token` вида <индекс>: <символ>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь вида <символ>:<индекс>\n",
    "# словарь вида <индекс>:<символ>\n",
    "token_to_id = {token:index for index,token in enumerate(tokens)}\n",
    "id_to_token = tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Комментарий: т.к. у нас всего 38 различных токенов, в этот раз воспользуемся one-hot encoding'ом.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша задача - создать и обучить рекуррентную нейронную сеть, которая сможет генерировать что-то похожее на поэзию Шекспира.\n",
    "\n",
    "Для начала воспользуемся классической RNN, аналогичной построенной на семинаре. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your modified code from class here\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def to_matrix(text, batch_size=32):\n",
    "    matrix = []\n",
    "    seq_len = int(len(text) / batch_size)\n",
    "      \n",
    "    for i in range(0, seq_len * batch_size, seq_len):\n",
    "        matrix.append([token_to_id[j] for j in text[i:i+seq_len]])\n",
    "\n",
    "    return torch.tensor(matrix, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "   \n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn = nn.RNN(embedding_size, rnn_num_units, batch_first = True)\n",
    "        self.linear = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        x_emb = self.embedding(x)\n",
    "        out, h_next = self.rnn(x_emb, h_prev)\n",
    "        \n",
    "        logits = self.linear(out)\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.num_units, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNN()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график функции потерь в зависимости от номера эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_ix = to_matrix(text, batch_size)\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "for i in range(1000):\n",
    "   \n",
    "    hidden_state = char_rnn.initial_state(batch_size)\n",
    "    fluff, logp_seq = char_rnn(batch_ix, hidden_state)\n",
    "\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))###YOUR CODE\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6446, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример сгенерированного текста. Функция `generate_text` отсутствует в коде выше.\n",
    "# print(generate_text(length=500, temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(char_rnn, max_length, seed_phrase = ' ',  temperature = 1.0):\n",
    "  \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([[x_sequence]], dtype=torch.long)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, :, i], hid_state)\n",
    "\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:,:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0].ravel()\n",
    "        \n",
    "        next_ix = np.random.choice(len(tokens),p=p_next)\n",
    "        next_ix = torch.tensor([[[next_ix]]], dtype=torch.long)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=2)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the see so the with the sure the world the sumper the see the say the with my shall shall shall the suest the worth the seet the seet in the self and the say the thee the self the say the rester the love thy see shall the with the seet the worth the summer the with the with the praise the all the worth the seet the prows the with the see the prown the so love the world be thee that the beauty the prown the stand the seet the say the seet the praine the wast the see the self the that the seet ha'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(char_rnn, max_length = 500, temperature = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Более поэтичная модель\n",
    "\n",
    "Теперь давайте воспользуемся LSTM слоем вместо классической RNN и сравним результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова постройте график функции потерь от числа эпох. Стал ли финальный loss лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, num_tokens=len(tokens), emb_size=16, num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.embedding = nn.Embedding(num_tokens, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, num_units, batch_first=True)\n",
    "        self.linear = nn.Linear(num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, hidden_state):\n",
    "        x_emb = self.embedding(x)\n",
    "        out, hidden_state = self.lstm(x_emb, hidden_state)\n",
    "        logits = self.linear(out)\n",
    "        return hidden_state, F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.num_units, requires_grad=True),\n",
    "                torch.zeros(1, batch_size, self.num_units, requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_lstm = CharLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_ix = to_matrix(text, batch_size)\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "opt = torch.optim.Adam(char_lstm.parameters())\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "   \n",
    "    hidden_state = tuple([hs for hs in char_lstm.initial_state(batch_size)])\n",
    "    fluff, logp_seq = char_lstm(batch_ix, hidden_state)\n",
    "\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))###YOUR CODE\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируйте текст с помощью обученной сети для различных значений параметра `temperature`: `[0.1, 0.2, 0.5, 1.0, 2.0]` (\"температуры\" при генерации). Оцените результаты визуально, попробуйте их проинтерпретировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature =  0.1 \n",
      "  the with should the seefur the seeple shall the self the self thee with the seeple so dear the self thee shall shall should the strees the seefur thee see the seefur the seet,\n",
      "  and the self the self the seeple so dear the streate,\n",
      "    the have the with the self and the self and thee shall the seefur the seeple the seemore the seefur thee the seet the seeple the seeple shall so deart,\n",
      "  and the with the sore the self the seemore doth shall should shall shall of the seemore the self thee the see \n",
      " -------------------- \n",
      "\n",
      "temperature =  0.2 \n",
      "  the with then thee so show,\n",
      "    the so shall my dights the self my seeple the seeple seet the seart,\n",
      "  the with the self the see the with thee with self the me the self the condering the seefur the sing thee with my seemore thee should the with the seefur the seem'd the self thee shall start,\n",
      "  the conting the with the self the self and the with the with sees in the dear thee the seeple time thee where the sore in the shall thee the sore the seemore thee with the seet,\n",
      "  the self the self the s \n",
      " -------------------- \n",
      "\n",
      "temperature =  0.5 \n",
      "  mithin with spart and beart,\n",
      "    out prows thee her for soren make desill a art the spite in the had her thee seart'd mige,\n",
      "  suel by with my should be rearty say desell\n",
      "  who werit seeth thou way the dodes for the make art me thee in the rethe as all the doth the respice,\n",
      "  and thee pring with then then me his eyed,\n",
      "  that for then fay,\n",
      "  that the wert i live proastar'd thee congiing, it thou fort the with thee my must sersing me,\n",
      "  ow and hath not be thy sine ot the prom so sweet in the with  \n",
      " -------------------- \n",
      "\n",
      "temperature =  1.0 \n",
      "  the hast as thy cakn in betaue face it nued where all his blev'd roies\n",
      "  to lut nolly ead assoon\n",
      "  uy fair best to my starture,\n",
      "  a pviren's fauly simbliisun's mave duth that sweet lath,\n",
      "  tive hers faet ielr's all revenctiging but earst to consterfown deept\n",
      "  the wimy daes the self to allent, bath mye:\n",
      "  and ae theed- to .i, for shinj ensceaf of ser'd's's,\n",
      "  thav' see mesh's so fand nelpuserared rlows pave i tom: groves bares grace:\n",
      "  si me pir'de,\n",
      "  the blind my ling hath cont'st got?\n",
      "    tha \n",
      " -------------------- \n",
      "\n",
      "temperature =  2.0 \n",
      "  soz densel' wput(whitg m'sior a--ylunzarr;\n",
      "  braud ovgigh, aregy mtundr.\n",
      "  thowc:c nnon.e;n de,.s bp'e dyplongw:t::\n",
      "  cuffoinmri;\n",
      "  yneiqge?q-ynt'st.\n",
      "  cogeay deai?-\n",
      "\n",
      " lx.zivi voj;wamy'slf axyint, thcy\n",
      " - sav' lock?, with nwarka-f'dozisuot yoints chan.\n",
      "\n",
      "  cxqoy knuatler igvpm wontgee no praskews yroslfausbhiou; to pro, limbumnd!-t wahagpigx\n",
      " ? mose eike.\n",
      "  ada\n",
      "\n",
      " hit.\n",
      "\n",
      "  chivigneggxouess vh,ntrze-ow in;m!: q sa deiknjsogve i arkaokoeik?, whatd, raaf frdyos:\n",
      "  i'my woik,-vin\n",
      "  menane sljoadlj ve\n",
      " \n",
      " -------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text generation with different tempearature values here\n",
    "for t in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
    "    print('temperature = ', t, '\\n', generate_text(char_lstm, max_length = 500, temperature = t), '\\n -------------------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь можно оставить свои рассуждения касательно интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем выше температура, тем более случайный набор текста мы получаем. При этом на низких температурах весь сгенерированный текст состоит буквально из нескольких слов. Вообще интересно получается, мне понравилось. Надо было раньше начинать лабу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение и загрузка модели\n",
    "\n",
    "Сохраните обученную модель на диск, затем загрузите ее и сгенерируйте текст. Примеры доступны по [ссылке](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chous they spove do to groend beand.\n",
      "  but all beant the loving awer thou will all and with gleand,\n",
      "  my send in thy heanting astent the samen with resell'd made thoush seeparion'd;\n",
      "  the but white and if astey thee whence whery cansely still steart not love ween prom my bearing these and with for my save breatty death agirst:\n",
      "    thou hame let shore as then dud is in of the with so she fors of me thou cantise ank or sweet tith pone,\n",
      "  though but the the from that hith it dith when my live, the call with loves hake my ton me,\n",
      "  when you are the place of than thou is ear it he ruld for to he w\n"
     ]
    }
   ],
   "source": [
    "# Saving and loading code here\n",
    "torch.save(char_lstm.state_dict(), 'Shakespeare_lstm.pt')\n",
    "char_lstm = CharLSTM()\n",
    "char_lstm.load_state_dict(torch.load('Shakespeare_lstm.pt'))\n",
    "char_lstm.eval()\n",
    "\n",
    "print(generate_text(char_lstm, max_length=600, temperature=0.66))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
